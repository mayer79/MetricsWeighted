% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classification.R
\name{classification}
\alias{classification}
\alias{accuracy}
\alias{classification_error}
\alias{precision}
\alias{recall}
\alias{f1_score}
\alias{AUC}
\alias{gini_coefficient}
\alias{deviance_bernoulli}
\alias{logLoss}
\title{Classification Metrics}
\usage{
accuracy(actual, predicted, w = NULL, ...)

classification_error(actual, predicted, w = NULL, ...)

precision(actual, predicted, w = NULL, ...)

recall(actual, predicted, w = NULL, ...)

f1_score(actual, predicted, w = NULL, ...)

AUC(actual, predicted, w = NULL, ...)

gini_coefficient(actual, predicted, w = NULL, ...)

deviance_bernoulli(actual, predicted, w = NULL, ...)

logLoss(actual, predicted, w = NULL, ...)
}
\arguments{
\item{actual}{Observed values.}

\item{predicted}{Predicted values.}

\item{w}{Optional case weights.}

\item{...}{Further arguments passed to \code{\link[=weighted_mean]{weighted_mean()}}
(no effect for \code{\link[=AUC]{AUC()}} and \code{\link[=gini_coefficient]{gini_coefficient()}}).}
}
\value{
A numeric vector of length one.
}
\description{
Case-weighted versions of typical non-probabilistic and probabilistic classification metrics:
\itemize{
\item 
\item \code{\link[=classification_error]{classification_error()}}: Classification error 1 - Accuracy (lower is better)
\item 
\item 
\item \code{\link[=f1_score]{f1_score()}}: F1 Score. Harmonic mean of precision and recall (higher is better)
\item \code{\link[=AUC]{AUC()}}: Area under the ROC (higher is better)
\item \code{\link[=gini_coefficient]{gini_coefficient()}}: Gini coefficient, equivalent to \eqn{2 \text{AUC} - 1}.
Up to ties in \code{predicted}, equivalent to Somer's D (higher is better)
\item \code{\link[=deviance_bernoulli]{deviance_bernoulli()}}: Average Bernoulli deviance, equals twice the
log loss/binary cross entropy (smaller is better)
\item \code{\link[=logLoss]{logLoss()}}: Log loss/binary cross entropy, equals half the average Bernoulli
deviance (smaller is better)
}
}
\details{
Note that the function \code{\link[=AUC]{AUC()}} was originally modified from the {glmnet} package
to ensure deterministic results. The unweighted version can be different from the
weighted one with unit weights due to ties in \code{predicted}.
}
\section{Input ranges}{

\itemize{
\item For \code{\link[=precision]{precision()}}, \code{\link[=recall]{recall()}}, and \code{\link[=f1_core]{f1_core()}}: The \code{actual} and \code{predicted} values
need to be in \eqn{\{0, 1\}}.
\item For \code{\link[=accuracy]{accuracy()}} and \code{\link[=classification_error]{classification_error()}}: Any discrete input.
\item For \code{\link[=AUC]{AUC()}} and \code{\link[=gini_coefficient]{gini_coefficient()}}: Only \code{actual} must be in \eqn{\{0, 1\}}.
\item For \code{\link[=deviance_bernoulli]{deviance_bernoulli()}} and \code{\link[=logLoss]{logLoss()}}: The values of \code{actual} must be in
\eqn{\{0, 1\}}, while \code{predicted} must be in the open interval \eqn{(0, 1)}.
}
}

\examples{
y <- c(0, 0, 1, 1)
pred <- c(0, 0, 1, 0)
w <- y * 2

accuracy(y, pred)
classification_error(y, pred, w = w)
precision(y, pred, w = w)
recall(y, pred, w = w)
f1_score(y, pred, w = w)

y2 <- c(0, 1, 0, 1)
pred2 <- c(0.1, 0.1, 0.9, 0.8)
w2 <- 1:4

AUC(y2, pred2)
AUC(y2, pred2, w = rep(1, 4))  # Different due to ties in predicted

gini_coefficient(y2, pred2, w = w2)
logLoss(y2, pred2, w = w2)
deviance_bernoulli(y2, pred2, w = w2)
}
